{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cleanliness Issue</td>\n",
       "      <td>The station's floor tiles are cracked and grimy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cleanliness Issue</td>\n",
       "      <td>The benches are covered in grime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luggage Issue</td>\n",
       "      <td>Luggage storage areas are frequently full.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cleanliness Issue</td>\n",
       "      <td>Food wrappers and litter are strewn across the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket Issue</td>\n",
       "      <td>Long queues at the ticketing counter are common.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Category                                               Text\n",
       "0  Cleanliness Issue   The station's floor tiles are cracked and grimy.\n",
       "1  Cleanliness Issue                  The benches are covered in grime.\n",
       "2      Luggage Issue         Luggage storage areas are frequently full.\n",
       "3  Cleanliness Issue  Food wrappers and litter are strewn across the...\n",
       "4       Ticket Issue   Long queues at the ticketing counter are common."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\SIH\\\\extra.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cleanliness Issue', 'Luggage Issue', 'Ticket Issue',\n",
       "       'Delay/Cancellation', 'Comfort Issue', 'Staff Behavior'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cleanliness Issue</td>\n",
       "      <td>The station's floor tiles are cracked and grimy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cleanliness Issue</td>\n",
       "      <td>The benches are covered in grime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luggage Issue</td>\n",
       "      <td>Luggage storage areas are frequently full.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cleanliness Issue</td>\n",
       "      <td>Food wrappers and litter are strewn across the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket Issue</td>\n",
       "      <td>Long queues at the ticketing counter are common.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Category                                               Text\n",
       "0  Cleanliness Issue   The station's floor tiles are cracked and grimy.\n",
       "1  Cleanliness Issue                  The benches are covered in grime.\n",
       "2      Luggage Issue         Luggage storage areas are frequently full.\n",
       "3  Cleanliness Issue  Food wrappers and litter are strewn across the...\n",
       "4       Ticket Issue   Long queues at the ticketing counter are common."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 188)\t0.4785269518125899\n",
      "  (0, 23)\t0.23062344709292057\n",
      "  (0, 95)\t0.4785269518125899\n",
      "  (0, 27)\t0.1384762444072018\n",
      "  (0, 434)\t0.42163640765914234\n",
      "  (0, 167)\t0.42163640765914234\n",
      "  (0, 408)\t0.3104611161785733\n",
      "  (0, 428)\t0.13311815419956677\n",
      "  (1, 187)\t0.534172980576192\n",
      "  (1, 204)\t0.3009514845141283\n",
      "  (1, 94)\t0.5137285753337059\n",
      "  (1, 48)\t0.5605304031212903\n",
      "  (1, 27)\t0.1545791055943739\n",
      "  (1, 428)\t0.1485979440201572\n",
      "  (2, 179)\t0.6549730583879672\n",
      "  (2, 176)\t0.33588779053483664\n",
      "  (2, 29)\t0.4188885727853154\n",
      "  (2, 411)\t0.4142178364033057\n",
      "  (2, 251)\t0.28714148234957493\n",
      "  (2, 27)\t0.16939717136030558\n",
      "  (3, 322)\t0.40345174138027745\n",
      "  (3, 8)\t0.40345174138027745\n",
      "  (3, 415)\t0.40345174138027745\n",
      "  (3, 246)\t0.40345174138027745\n",
      "  (3, 488)\t0.40345174138027745\n",
      "  :\t:\n",
      "  (496, 229)\t0.19747182096862162\n",
      "  (496, 430)\t0.2214815760620015\n",
      "  (496, 411)\t0.39152228248663484\n",
      "  (496, 251)\t0.2714086132607788\n",
      "  (497, 449)\t0.5769465379283206\n",
      "  (497, 405)\t0.5124824199326758\n",
      "  (497, 480)\t0.5032285338560181\n",
      "  (497, 23)\t0.2988387695169211\n",
      "  (497, 27)\t0.1794356601967681\n",
      "  (497, 428)\t0.1724927187708463\n",
      "  (498, 97)\t0.5459576652279373\n",
      "  (498, 52)\t0.4887261671837712\n",
      "  (498, 290)\t0.44570588141033124\n",
      "  (498, 424)\t0.3652140023503672\n",
      "  (498, 176)\t0.3257347543045914\n",
      "  (498, 428)\t0.1579203308327122\n",
      "  (499, 236)\t0.4711051968081124\n",
      "  (499, 41)\t0.4711051968081124\n",
      "  (499, 279)\t0.3076129752626417\n",
      "  (499, 173)\t0.2582280909264847\n",
      "  (499, 193)\t0.34662318104538375\n",
      "  (499, 34)\t0.38459823966879014\n",
      "  (499, 229)\t0.17482609244163447\n",
      "  (499, 430)\t0.19608245014810047\n",
      "  (499, 251)\t0.2402839406586748\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 3 0 5 5 2 5 1 0 3 4 5 5 3 1 1 0 1 5 4 5 3 0 5 0 1 2 4 2 0 3 2 5 2 2 5\n",
      " 4 0 2 3 2 3 5 0 4 0 3 5 5 4 0 1 4 2 3 4 1 2 1 2 5 4 2 4 0 3 3 2 3 2 4 3 4\n",
      " 1 0 2 1 3 5 4 2 0 3 5 0 3 2 1 0 0 0 0 3 5 4 0 4 3 4 4 4 0 2 3 3 2 0 1 4 1\n",
      " 5 4 3 0 4 4 5 5 3 3 4 2 5 4 0 5 2 2 5 4 2 4 4 0 3 2 1 4 5 3 2 3 0 5 2 3 0\n",
      " 4 2 4 2 5 5 3 5 4 4 2 4 2 4 5 0 2 3 2 4 0 4 5 3 4 5 5 1 3 4 4 4 5 3 3 4 5\n",
      " 5 5 5 1 4 5 1 2 1 1 0 5 0 0 3 0 1 5 3 3 1 5 4 4 4 0 4 1 0 2 4 4 2 0 4 4 5\n",
      " 3 3 3 0 4 5 5 4 2 1 0 2 5 3 3 4 5 0 1 3 0 2 3 3 2 2 0 2 0 1 2 0 5 4 5 3 1\n",
      " 0 3 2 5 2 0 3 2 1 4 4 2 5 1 0 5 2 0 1 3 3 2 5 2 4 1 3 2 1 4 5 5 5 5 2 0 5\n",
      " 2 1 3 0 4 2 1 5 5 0 0 3 4 1 5 1 4 5 4 0 3 0 5 3 1 0 5 1 2 1 0 5 1 2 1 0 2\n",
      " 3 5 0 4 5 4 5 2 5 1 2 0 2 5 4 0 5 2 2 1 0 1 2 5 5 1 4 4 0 2 3 5 3 3 2 4 3\n",
      " 4 5 4 1 5 3 2 5 0 1 5 3 3 5 5 2 2 5 5 2 5 3 5 4 2 1 3 3 4 2 3 1 3 4 3 2 2\n",
      " 5 5 3 4 3 1 5 5 3 4 1 1 3 3 5 0 5 5 3 2 1 1 2 2 2 3 3 2 3 0 3 0 4 0 3 1 4\n",
      " 3 2 4 1 2 0 2 1 2 3 3 0 4 1 4 3 4 2 0 4 0 3 2 1 3 0 0 4 0 1 0 4 4 5 4 3 1\n",
      " 0 4 0 5 3 0 0 3 0 2 2 3 4 3 5 3 0 5 3]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"xgb_model\" : XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naive Bayes\n",
      "Accuracy: 0.96\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       1.00      0.94      0.97        16\n",
      "           3       1.00      1.00      1.00        22\n",
      "           4       0.87      0.93      0.90        14\n",
      "           5       0.96      0.96      0.96        23\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.96      0.95      0.96       100\n",
      "weighted avg       0.96      0.96      0.96       100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        22\n",
      "           4       1.00      0.93      0.96        14\n",
      "           5       0.96      1.00      0.98        23\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.99      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        22\n",
      "           4       1.00      1.00      1.00        14\n",
      "           5       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.98\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       1.00      0.94      0.97        16\n",
      "           3       1.00      1.00      1.00        22\n",
      "           4       1.00      1.00      1.00        14\n",
      "           5       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           0.98       100\n",
      "   macro avg       0.98      0.97      0.98       100\n",
      "weighted avg       0.98      0.98      0.98       100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: xgb_model\n",
      "Accuracy: 0.95\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        16\n",
      "           1       1.00      0.78      0.88         9\n",
      "           2       0.84      1.00      0.91        16\n",
      "           3       1.00      1.00      1.00        22\n",
      "           4       0.93      1.00      0.97        14\n",
      "           5       1.00      0.96      0.98        23\n",
      "\n",
      "    accuracy                           0.95       100\n",
      "   macro avg       0.95      0.93      0.94       100\n",
      "weighted avg       0.95      0.95      0.95       100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naive Bayes\n",
      "Accuracy: 0.96\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       1.00      0.94      0.97        16\n",
      "           3       1.00      1.00      1.00        22\n",
      "           4       0.87      0.93      0.90        14\n",
      "           5       0.96      0.96      0.96        23\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.96      0.95      0.96       100\n",
      "weighted avg       0.96      0.96      0.96       100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        22\n",
      "           4       1.00      0.93      0.96        14\n",
      "           5       0.96      1.00      0.98        23\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.99      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        22\n",
      "           4       1.00      1.00      1.00        14\n",
      "           5       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.98\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       1.00      0.94      0.97        16\n",
      "           3       1.00      1.00      1.00        22\n",
      "           4       1.00      1.00      1.00        14\n",
      "           5       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           0.98       100\n",
      "   macro avg       0.98      0.97      0.98       100\n",
      "weighted avg       0.98      0.98      0.98       100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: xgb_model\n",
      "Accuracy: 0.95\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        16\n",
      "           1       1.00      0.78      0.88         9\n",
      "           2       0.84      1.00      0.91        16\n",
      "           3       1.00      1.00      1.00        22\n",
      "           4       0.93      1.00      0.97        14\n",
      "           5       1.00      0.96      0.98        23\n",
      "\n",
      "    accuracy                           0.95       100\n",
      "   macro avg       0.95      0.93      0.94       100\n",
      "weighted avg       0.95      0.95      0.95       100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nn_model = Sequential([\n",
    "    Dense(512, input_dim=X_train_dense.shape[1], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2116 - loss: 1.7878 - val_accuracy: 0.4875 - val_loss: 1.7447\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4547 - loss: 1.7134 - val_accuracy: 0.6500 - val_loss: 1.6695\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6535 - loss: 1.6005 - val_accuracy: 0.7750 - val_loss: 1.5267\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7926 - loss: 1.4110 - val_accuracy: 0.8000 - val_loss: 1.2859\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9146 - loss: 1.0896 - val_accuracy: 0.9000 - val_loss: 0.9313\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9640 - loss: 0.6948 - val_accuracy: 0.9250 - val_loss: 0.6025\n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9637 - loss: 0.3743 - val_accuracy: 0.9375 - val_loss: 0.3499\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9813 - loss: 0.2001 - val_accuracy: 0.9375 - val_loss: 0.2347\n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0893 - val_accuracy: 0.9500 - val_loss: 0.1796\n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0618 - val_accuracy: 0.9500 - val_loss: 0.1445\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.0395 - val_accuracy: 0.9500 - val_loss: 0.1326\n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.9500 - val_loss: 0.1285\n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.9500 - val_loss: 0.1271\n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9991 - loss: 0.0185 - val_accuracy: 0.9500 - val_loss: 0.1216\n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9500 - val_loss: 0.1170\n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9375 - val_loss: 0.1180\n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9375 - val_loss: 0.1173\n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9375 - val_loss: 0.1169\n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.9375 - val_loss: 0.1155\n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9375 - val_loss: 0.1161\n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9375 - val_loss: 0.1155\n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9375 - val_loss: 0.1073\n",
      "Epoch 23/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9375 - val_loss: 0.1038\n",
      "Epoch 24/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9375 - val_loss: 0.1035\n",
      "Epoch 25/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9375 - val_loss: 0.1042\n",
      "Epoch 26/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9500 - val_loss: 0.1081\n",
      "Epoch 27/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9500 - val_loss: 0.1084\n",
      "Epoch 28/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9500 - val_loss: 0.1095\n",
      "Epoch 29/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9500 - val_loss: 0.1097\n",
      "Epoch 30/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9500 - val_loss: 0.1090\n",
      "Epoch 31/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9500 - val_loss: 0.1092\n",
      "Epoch 32/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9500 - val_loss: 0.1101\n",
      "Epoch 33/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9500 - val_loss: 0.1099\n",
      "Epoch 34/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9500 - val_loss: 0.1082\n",
      "Epoch 35/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9500 - val_loss: 0.1110\n",
      "Epoch 36/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9500 - val_loss: 0.1107\n",
      "Epoch 37/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9500 - val_loss: 0.1105\n",
      "Epoch 38/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9375 - val_loss: 0.1099\n",
      "Epoch 39/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9375 - val_loss: 0.1072\n",
      "Epoch 40/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7516e-04 - val_accuracy: 0.9375 - val_loss: 0.1059\n",
      "Epoch 41/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9375 - val_loss: 0.1067\n",
      "Epoch 42/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9375 - val_loss: 0.1082\n",
      "Epoch 43/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9375 - val_loss: 0.1079\n",
      "Epoch 44/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9375 - val_loss: 0.1088\n",
      "Epoch 45/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 8.0460e-04 - val_accuracy: 0.9375 - val_loss: 0.1078\n",
      "Epoch 46/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9375 - val_loss: 0.1058\n",
      "Epoch 47/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9375 - val_loss: 0.1018\n",
      "Epoch 48/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.8319e-04 - val_accuracy: 0.9375 - val_loss: 0.1001\n",
      "Epoch 49/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 8.4345e-04 - val_accuracy: 0.9375 - val_loss: 0.1001\n",
      "Epoch 50/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9500 - val_loss: 0.0995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x194cecf1f00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.fit(X_train_dense, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Neural Network Model Accuracy: 0.94\n",
      "Neural Network Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       1.00      0.81      0.90        16\n",
      "           3       0.96      1.00      0.98        22\n",
      "           4       0.87      0.93      0.90        14\n",
      "           5       0.92      0.96      0.94        23\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.95      0.93      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = nn_model.predict(X_test_dense)\n",
    "y_pred_nn_classes = y_pred_nn.argmax(axis=1)\n",
    "print(\"Neural Network Model Accuracy:\", accuracy_score(y_test, y_pred_nn_classes))\n",
    "print(\"Neural Network Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe(value):\n",
    "    vectorized_value = TfidfVectorizer.fit_transform(value) # You can switch to TfidfVectorizer() if needed\n",
    "    print(nn_model.predict(vectorized_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TfidfVectorizer.fit_transform() missing 1 required positional argument: 'raw_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe chapathi served today morning is awful\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipe\u001b[39m(value):\n\u001b[1;32m----> 2\u001b[0m     vectorized_value \u001b[38;5;241m=\u001b[39m \u001b[43mTfidfVectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# You can switch to TfidfVectorizer() if needed\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(nn_model\u001b[38;5;241m.\u001b[39mpredict(vectorized_value))\n",
      "\u001b[1;31mTypeError\u001b[0m: TfidfVectorizer.fit_transform() missing 1 required positional argument: 'raw_documents'"
     ]
    }
   ],
   "source": [
    "pipe(value=\"The chapathi served today morning is awful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('D:\\\\SIH\\\\extra.csv')\n",
    "\n",
    "# Vectorize the 'Text' column\n",
    "vectorizer = TfidfVectorizer(max_features=500)  # Adjust max_features if necessary\n",
    "X = vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Encode the 'Category' column\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Category'])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model, vectorizer, and label encoder\n",
    "joblib.dump(model, \"xgboost_model.pkl\")\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the TfidfVectorizer\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
    "\n",
    "# Save the XGBoost model\n",
    "joblib.dump(model, \"xgboost_model.pkl\")\n",
    "\n",
    "# Save the LabelEncoder (optional but recommended if you need to decode labels)\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: Delay/Cancellation\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained components\n",
    "model = joblib.load(\"xgboost_model.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "# Take user input\n",
    "inp = input(\"Enter your text (or type 'exit' to quit): \")\n",
    "\n",
    "while inp.lower() != 'exit':\n",
    "    # Transform the input using the same vectorizer\n",
    "    vec = vectorizer.transform([inp])\n",
    "\n",
    "    # Predict the category\n",
    "    pred = model.predict(vec)\n",
    "\n",
    "    # Decode the predicted label back to the original category name\n",
    "    pred_label = label_encoder.inverse_transform(pred)\n",
    "\n",
    "    # Display the predicted category\n",
    "    \n",
    "    print(\"Predicted Category:\", pred_label[0])\n",
    "\n",
    "    # Ask for another input\n",
    "    inp = input(\"Enter your text (or type 'exit' to quit): \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
